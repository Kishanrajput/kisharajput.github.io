---
title: "An Outlook Towards Deployable Continual Learning for Particle Accelerators"
authors: 
  - Rajput, K.
  - Lin, S.
  - Edelen, A.
  - Blokland, W.
  - Schram, M.

date: "2025-07-11"
doi: "https://doi.org/10.1088/2632-2153/adeb45"


# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article-journal"]

# Publication name and optional abbreviated publication name.
publication: "Machine Learning: Science and Technology, Volume 6, Number 3, Article 031001"
publication_short: "MLST"

abstract: Particle accelerators are high power complex machines. To ensure uninterrupted operation of these machines, thousands of pieces of equipment need to be synchronized, which requires addressing many challenges including design, optimization and control, anomaly detection and machine protection. With recent advancements, machine learning (ML) holds promise to assist in more advance prognostics, optimization, and control. While ML based solutions have been developed for several applications in particle accelerators, only few have reached deployment and even fewer to long term usage, due to particle accelerator data distribution drifts caused by changes in both measurable and non-measurable parameters. In this paper, we identify some of the key areas within particle accelerators where continual learning can allow maintenance of ML model performance with distribution drifts. Particularly, we first discuss existing applications of ML in particle accelerators, and their limitations due to distribution drift. Next, we review existing continual learning techniques and investigate their potential applications to address data distribution drifts in accelerators. By identifying the opportunities and challenges in applying continual learning, this paper seeks to open up the new field and inspire more research efforts towards deployable continual learning for particle accelerators.

# Summary. An optional shortened abstract.
summary: Particle accelerators rely on the precise synchronization of thousands of components, but data distribution drifts often limit the long-term deployment of machine learning solutions. This paper explores how continual learning can overcome these drifts, reviewing current ML applications, identifying key challenges, and highlighting opportunities to enable robust, deployable AI for accelerator operations.

tags:
- Continual Learning
- Machine Learning
- Deployment
- Particle Accelerator
- Data Drift

featured: true

url_pdf: 'https://iopscience.iop.org/article/10.1088/2632-2153/adeb45/pdf'
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: 'https://iopscience.iop.org/article/10.1088/2632-2153/adeb45'
url_video: ''
# url_video: '#'


# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: 'Image credit: [**MLST**](https://iopscience.iop.org/article/10.1088/2632-2153/adeb45/meta)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
- internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

This work is driven by the results in my [previous paper](/publication/conference-paper/) on LLMs.

<!-- {{% callout note %}} -->

<!-- {{% /callout %}} -->

<!-- Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
